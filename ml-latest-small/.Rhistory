grep(" [[:alpha:]]{2}'", someText, value = T)
# Contraction beginning with 3 letters
grep(" [[:alpha:]]{3}'", someText, value = T)
example.obj
# Greedy matching
str_extract(example.obj, "A.+sentence")
library(stringr)
example.obj
# Greedy matching
str_extract(example.obj, "A.+sentence")
# Greedy matching
str_extract(example.obj, "A.+sentence")
example.obj
example.obj
# Greedy matching
str_extract(example.obj, "A.+sentence")
str_extract(example.obj, "A.+?sentence")
# Greedy matching
str_extract(example.obj, "A.+sentenc")
example.obj
# Greedy matching
str_extract(example.obj, "A.+sentenc")
str_extract(example.obj, "A.+?sentence")
example.obj
# Greedy matching
str_extract(example.obj, "A.+sentence")
str_extract(example.obj, "A.+?sentence")
example.obj
# Greedy matching
str_extract(example.obj, "A.+sentence")
str_extract(example.obj, "A.+?sentence")
str_extract(example.obj, "A.+?sentenc")
str_extract(example.obj, "A.+?")
# Greedy matching
str_extract(example.obj, "A.+")
str_extract(example.obj, "A.+?")
e
str_extract(example.obj, "A.+?sentence")
str_extract(example.obj, "A.+?sentence")
example.obj
# Greedy matching
str_extract(example.obj, "A.+sentence")
# Greedy matching
str_extract(example.obj, "A.+er")
example.obj
# Greedy matching
str_extract(example.obj, "A.+er")
# Greedy matching
str_extract(example.obj, "A.?er")
# Greedy matching
str_extract(example.obj, "A.?er")
example.obj
# Greedy matching
str_extract(example.obj, "A.?er")
str_extract(example.obj, "A.+?sentence")
str_extract(example.obj, "A.+?")
example.obj
# Greedy matching
str_extract(example.obj, "A.?er")
str_extract(example.obj, "A.+?")
str_extract(example.obj, "A.+")
# Greedy matching
str_extract(example.obj, "A.?er")
# Greedy matching
str_extract(example.obj, "A.?)
# Greedy matching
str_extract(example.obj, "A.?)
example.obj
# Greedy matching
str_extract(example.obj, "A.?")
str_extract(example.obj, "A.+")
str_extract(example.obj, "A.+er")
str_extract(example.obj, "A.+?er")
str_extract(example.obj, "A.+?er")
str_extract(example.obj, "A.+?sentence")
example.obj
example.obj
# Greedy matching
str_extract(example.obj, "A.?")
str_extract(example.obj, "A.+?sentence")
example.obj <- "1. A small lol. - 2. Another tiny sentence."
str_extract(example.obj, "A.+?sentence")
str_extract(example.obj, "A.+?lol")
str_extract(example.obj, "A.+?")
str_extract(example.obj, "A.?")
str_extract(example.obj, "A..?")
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){1,5}"))
unlist(str_extract_all(example.obj, ".en{1,5}"))
example.obj <- "1. A small sentence. - 2. Another tiny sentence."
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){1,5}"))
example.obj <- "1. A small. - 2. Another tiny sentence."
# Greedy matching
str_extract(example.obj, "A.?")
example.obj <- "1. A small. - 2. Another tiny sentence."
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){1,5}"))
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){2,5}"))
example.obj <- "1. A small. - 2. Another tiny sentence."
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){2,5}"))
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){3,5}"))
example.obj <- "1. A small sentence. - 2. Another tiny sentence."
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){3,5}"))
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){2,5}"))
example.obj <- "1. A small sentence. - 2. Another tiny sentence."
unlist(str_extract_all(example.obj, ".en{1,5}"))
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){3,5}"))
unlist(str_extract_all(example.obj, ".en{1,5}"))
unlist(str_extract_all(example.obj, ".en{2,5}"))
unlist(str_extract_all(example.obj, ".en{1,5}"))
unlist(str_extract_all(example.obj, ".en{1,4}"))
unlist(str_extract_all(example.obj, ".en{1,3}"))
unlist(str_extract_all(example.obj, ".en{1,2}"))
unlist(str_extract_all(example.obj, ".en{1,}"))
unlist(str_extract_all(example.obj, ".en{1}"))
example.obj <- "1. A small sentence. - 2. Another tiny sentence."
unlist(str_extract_all(example.obj, ".en{1}"))
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){3,5}"))
unlist(str_extract_all(example.obj, ".en{1}"))
unlist(str_extract_all(example.obj, ".en{1,5}"))
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){3,5}"))
unlist(str_extract_all(example.obj, ".en{1,5}"))
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){1,5}"))
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){1,6}"))
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){1,6}"))
unlist(str_extract_all(example.obj, ".en{1,5}"))
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){1,}"))
example.obj <- "1. A small sentence. - 2. Another tiny fucsentence."
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){1,5}"))
example.obj <- "1. A small sentence. - 2. Another tiny fucsentence."
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){1,5}"))
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){1,2}"))
unlist(str_extract_all(example.obj, ".en{1,5}"))
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){2,5}"))
unlist(str_extract_all(example.obj, ".en{1,5}"))
unlist(str_extract_all(example.obj, ".en{1}"))
unlist(str_extract_all(example.obj, ".en{0}"))
unlist(str_extract_all(example.obj, ".en{1}"))
unlist(str_extract_all(example.obj, ".en{1,8}"))
unlist(str_extract_all(example.obj, ".en{2,8}"))
unlist(str_extract_all(example.obj, ".en{2,5}"))
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){2,5}"))
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){2,4}"))
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){2,4}"))
example.obj <- "1. A small sentence. - 2. Another tiny ."
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){2,4}"))
example.obj <- "1. A small sentence sentence sentence sentence sentence. - 2. Another tiny ."
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){2,4}"))
example.obj <- "1. A small sentence sentence sentence sentence sentence. - 2. Another tiny ."
# Quantifying a group of characters
unlist(str_extract_all(example.obj, "(.en){2,4}"))
unlist(str_extract_all(example.obj, ".en{2,5}"))
unlist(str_extract_all(example.obj, ".en{1,5}"))
# Contraction beginning with 3 letters
grep(" [[:alpha:]]{3}'", someText, value = T)
# Contraction beginning with 3 letters
grep(" [[:alpha:]]{3}'", example.obj, value = T)
# Contraction beginning with 3 letters
grep(" s[[:alpha:]]{3}t'", example.obj, value = T)
# Contraction beginning with 3 letters
grep(" s[[:alpha:]]{2}t'", example.obj, value = T)
# Contraction beginning with 3 letters
grep("s[[:alpha:]]{2}t'", example.obj, value = T)
someText
# Contraction beginning with 3 letters
grep(" [[:alpha:]]{3}'", someText, value = T)
someText
# Contraction beginning with 3 letters
grep(" [[:alpha:]]{3}'", someText, value = T)
grep("\\b[[:alpha:]]{3}'", someText, value = T)
grep("\\b[[:alpha:]]{3}'", example.obj, value = T)
grep("[[:alpha:]]{3}'", someText, value = T)
grep("\\b[[:alpha:]]{3}'", someText, value = T)
grep("\\b[[:alpha:]]{3}'", someText, value = T)
grep("\\b[[:alpha:]]{4}'", someText, value = T)
grep("\\b[[:alpha:]]{5}'", someText, value = T)
someText <- c("  here's a sentence",
"This is me typing at 2:02 in the morning",
"Back in 1995 I was only 22.",
" You saw 4 monkeys?",
"There are 10 kinds of people,    those that understand binary
and the other 9 that don't care",
"Who likes pancakes? I do. I really really like pancakes!",
"     <strong>Bolded text is bold and daring</strong>",
"figure1.jpg", "cover.jpg", "report.pdf", "log.txt",
"I'm a one man wolfpack and I weigh 222",
"OMG, a 3-eyed cyclops!!!",
"2112 is an awesome album.",
"2222 is my PIN")
# Contraction beginning with 3 letters
grep(" [[:alpha:]]{3}'", someText, value = T)
grep("\\b[[:alpha:]]{3}'", someText, value = T)
someText <- c("  here's a sentence",
"This is me typing at 2:02 in the morning",
"Back in 1995 I was only 22.",
" Yo saw 4 monkeys?",
"There are 10 kinds of people,    those that understand binary
and the other 9 that don't care",
"Who likes pancakes? I do. I really really like pancakes!",
"     <strong>Bolded text is bold and daring</strong>",
"figure1.jpg", "cover.jpg", "report.pdf", "log.txt",
"I'm a one man wolfpack and I weigh 222",
"OMG, a 3-eyed cyclops!!!",
"2112 is an awesome album.",
"2222 is my PIN")
grep("\\b[[:alpha:]]{2}'", someText, value = T)
grep("\\b[[:alpha:]]{3}'", someText, value = T)
grep("\\b[[:alpha:]]{4}'", someText, value = T)
grep("\\b[[:alpha:]]{5}'", someText, value = T)
grep("\\b[[:alpha:]]{4}'", someText, value = T)
install.packages("RMongo")
install.packages("mongolite")
knitr::opts_chunk$set(echo = TRUE)
library(mongolite)
install.packages("devtools")
library(devtools)
knitr::opts_chunk$set(echo = TRUE)
# Load H2O and start up a local H2O cluster
library(h2o)
h2o.init(nthreads = -1)
# Load H2O and start up a local H2O cluster
library(h2o)
h2o.init(nthreads = -1)
# Import movie lens datasets
# ratings file can be found here: http://grouplens.org/datasets/movielens/1m/
ratings <- h2o.importFile("rating_edx.csv", sep = ":")
# Import movie lens datasets
# ratings file can be found here: http://grouplens.org/datasets/movielens/1m/
ratings <- h2o.importFile("rating_edx.csv", sep = ":")
setwd("~/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small")
# Import movie lens datasets
# ratings file can be found here: http://grouplens.org/datasets/movielens/1m/
ratings <- h2o.importFile("rating_edx.csv", sep = ":")
# Import movie lens datasets
# ratings file can be found here: http://grouplens.org/datasets/movielens/1m/
ratings <- h2o.importFile("rating_edx.csv", sep = ",")
setwd("~/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small")
# movies file can be found here: http://grouplens.org/datasets/movielens/20m/
movies <- h2o.importFile("movies.csv", sep = ",")
# Import movie lens datasets
# ratings file can be found here: http://grouplens.org/datasets/movielens/1m/
ratings <- h2o.importFile("rating_edx.csv",T)
# Import movie lens datasets
# ratings file can be found here: http://grouplens.org/datasets/movielens/1m/
ratings <- h2o.importFile("rating_edx.csv",sep = ',')
# Import movie lens datasets
# ratings file can be found here: http://grouplens.org/datasets/movielens/1m/
ratings <- h2o.importFile("rating_edx.csv",sep = ':')
setwd("~/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small")
?h2o.importFile
# Import movie lens datasets
# ratings file can be found here: http://grouplens.org/datasets/movielens/1m/
ratings <- h2o.importFile("/Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/rating_edx.csv",sep = ':')
#?h2o.importFile
#ratings <- ratings[c(1, 3, 5, 7)]
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
#?h2o.importFile
#ratings <- ratings[c(1, 3, 5, 7)]
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
#?h2o.importFile
#ratings <- ratings[c(1, 3, 5, 7)]
#colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
# movies file can be found here: http://grouplens.org/datasets/movielens/20m/
movies <- h2o.importFile("/Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/movies.csv", sep = ":")
#?h2o.importFile
#ratings <- ratings[c(1, 3, 5, 7)]
#colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
# movies file can be found here: http://grouplens.org/datasets/movielens/20m/
movies <- h2o.importFile("/Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/movies.csv, sep = ":")
# Import movie lens datasets
# ratings file can be found here: http://grouplens.org/datasets/movielens/1m/
ratings <- h2o.importFile("/Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/rating_edx.csv",sep = ':')
#?h2o.importFile
#ratings <- ratings[c(1, 3, 5, 7)]
#colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
# movies file can be found here: http://grouplens.org/datasets/movielens/20m/
movies <- h2o.importFile("/Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/movies.csv, sep = ":")
#?h2o.importFile
#ratings <- ratings[c(1, 3, 5, 7)]
#colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
#?h2o.importFile
#ratings <- ratings[c(1, 3, 5, 7)]
#colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
# movies file can be found here: http://grouplens.org/datasets/movielens/20m/
movies <- h2o.importFile("/Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/movies.csv, sep = ":")
library('pander')
sub_ratings <- as.data.frame(ratings[c(1:5), ])
pandoc.table(sub_ratings, style = "rmarkdown", caption = "Ratings Dataset")
h2o.hist(ratings$rating, breaks = seq(0, 5, 1))
## Group Data by movieId
ratings_per_movie <- h2o.group_by(ratings, by = "movieId", nrow("rating"))
colnames(ratings_per_movie)[[2]] <- "numberRatings"
#?h2o.importFile
#ratings <- ratings[c(1, 3, 5, 7)]
#colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
# movies file can be found here: http://grouplens.org/datasets/movielens/20m/
movies <- h2o.importFile("/Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/movies.csv, sep = ":")
#?h2o.importFile
#ratings <- ratings[c(1, 3, 5, 7)]
#colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
#?h2o.importFile
#ratings <- ratings[c(1, 3, 5, 7)]
#colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
# movies file can be found here: http://grouplens.org/datasets/movielens/20m/
movies <- h2o.importFile("/Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/movies.csv",sep = ',')
library('pander')
install.packages("pander")
sub_ratings <- as.data.frame(ratings[c(1:5), ])
library('pander')
library('pander')
sub_ratings <- as.data.frame(ratings[c(1:5), ])
h2o.hist(ratings$rating, breaks = seq(0, 5, 1))
library('pander')
sub_ratings <- as.data.frame(ratings[c(1:5), ])
pandoc.table(sub_ratings, style = "rmarkdown", caption = "Ratings Dataset")
sub_movies <- as.data.frame(movies[c(1:5), ])
View(sub_movies)
sub_ratings <- as.data.frame(ratings[c(1:5), ])
pandoc.table(sub_ratings, style = "rmarkdown", caption = "Ratings Dataset")
sub_movies <- as.data.frame(movies[c(1:5), ])
sub_movies$genres <- gsub("\\|", ",", sub_movies$genres)
pandoc.table(sub_movies, style = "rmarkdown", caption = "Movies Dataset")
h2o.hist(ratings$rating, breaks = seq(0, 5, 1))
## Group Data by movieId
ratings_per_movie <- h2o.group_by(ratings, by = "movieId", nrow("rating"))
## Group Data by movieId
ratings_per_movie <- h2o.group_by(ratings, by = "movieId", nrow("rating"))
## Group Data by userId
ratings_per_user <- h2o.group_by(ratings, by = "userId", nrow("rating"))
colnames(ratings_per_user)[[2]] <- "numberRatings"
View(movies)
# The following two commands remove any previously installed H2O packages for R.
if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }
# Next, we download packages that H2O depends on.
pkgs <- c("RCurl","jsonlite")
for (pkg in pkgs) {
if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}
# Now we download, install and initialize the H2O package for R.
install.packages("h2o", type="source", repos="http://h2o-release.s3.amazonaws.com/h2o/rel-wright/2/R")
# Finally, let's load H2O and start up an H2O cluster
library(h2o)
h2o.init()
#?h2o.importFile
#ratings <- ratings[c(1, 3, 5, 7)]
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
h2o.init()
# Load H2O and start up a local H2O cluster
library(h2o)
h2o.init(nthreads = -1)
# Load H2O and start up a local H2O cluster
library(h2o)
h2o.init(nthreads = -1)
# Load H2O and start up a local H2O cluster
library(h2o)
h2o.init(nthreads = -1)
h2o.init(nthreads = -1)
h2o.init(nthreads = -1)
# Load H2O and start up a local H2O cluster
library(h2o)
h2o.init(nthreads = -1)
# The following two commands remove any previously installed H2O packages for R.
if ("package:h2o" %in% search()) { detach("package:h2o", unload=TRUE) }
if ("h2o" %in% rownames(installed.packages())) { remove.packages("h2o") }
# Next, we download packages that H2O depends on.
pkgs <- c("RCurl","jsonlite")
for (pkg in pkgs) {
if (! (pkg %in% rownames(installed.packages()))) { install.packages(pkg) }
}
# Now we download, install and initialize the H2O package for R.
install.packages("h2o", type="source", repos="http://h2o-release.s3.amazonaws.com/h2o/rel-wright/2/R")
# Now we download, install and initialize the H2O package for R.
install.packages("h2o", type="source", repos="http://h2o-release.s3.amazonaws.com/h2o/rel-wright/2/R")
# Finally, let's load H2O and start up an H2O cluster
library(h2o)
h2o.init()
# Finally, let's load H2O and start up an H2O cluster
library(h2o)
h2o.init()
# Load H2O and start up a local H2O cluster
library(h2o)
h2o.init(nthreads = -1)
#?h2o.importFile
#ratings <- ratings[c(1, 3, 5, 7)]
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
# Load H2O and start up a local H2O cluster
library(h2o)
h2o.init(nthreads = -1)
#Load the H2O R package and start an local H2O cluster
library(h2o)
# h2o.init functions connect to H2O. Will use default options
h2o.init()
# Starts H2O using localhost IP, port 54321, all CPUs, and 2g of memory
h2o.init(ip = "localhost", port = 54321, nthreads= -1, max_mem_size = "2g")
# To check the status and health of the H2O cluster, use
h2o.clusterInfo()
# To import small iris data file from H2O's package:
irisPath = system.file("extdata", "iris.csv", package="h2o")
iris.hex = h2o.importFile(path = irisPath, destination_frame = "iris.hex")
# Load H2O and start up a local H2O cluster
library(h2o)
h2o.init(nthreads = -1)
h2o.init(nthreads = -1)
h2o.init(nthreads = -1)
knitr::opts_chunk$set(echo = TRUE)
# Load H2O and start up a local H2O cluster
library(h2o)
h2o.init(nthreads = -1)
h2o.init(nthreads = -1)
# Import movie lens datasets
# ratings file can be found here: http://grouplens.org/datasets/movielens/1m/
ratings <- h2o.importFile("/Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/rating_edx.csv", sep = ":")
ratings <- ratings[c(1, 3, 5, 7)]
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
# movies file can be found here: http://grouplens.org/datasets/movielens/20m/
movies <- h2o.importFile("/Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/movies.csv", sep = ",")
# Import movie lens datasets
# ratings file can be found here: http://grouplens.org/datasets/movielens/1m/
ratings <- h2o.importFile("/Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/rating_edx.csv", sep = ":")
ratings <- ratings[c(1, 3, 5, 7)]
#colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
# movies file can be found here: http://grouplens.org/datasets/movielens/20m/
movies <- h2o.importFile("/Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/movies.csv", sep = ",")
# Load H2O and start up a local H2O cluster
library(h2o)
h2o.init(nthreads = -1)
library('pander')
sub_ratings <- as.data.frame(ratings[c(1:5), ])
pandoc.table(sub_ratings, style = "rmarkdown", caption = "Ratings Dataset")
sub_movies <- as.data.frame(movies[c(1:5), ])
sub_movies$genres <- gsub("\\|", ",", sub_movies$genres)
pandoc.table(sub_movies, style = "rmarkdown", caption = "Movies Dataset")
h2o.hist(ratings$rating, breaks = seq(0, 5, 1))
## Group Data by movieId
ratings_per_movie <- h2o.group_by(ratings, by = "movieId", nrow("rating"))
## Group Data by userId
ratings_per_user <- h2o.group_by(ratings, by = "userId", nrow("rating"))
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
h2o.hist(ratings$rating, breaks = seq(0, 5, 1))
## Group Data by movieId
ratings_per_movie <- h2o.group_by(ratings, by = "movieId", nrow("rating"))
## Change Data Types
ratings$userId <- as.factor(ratings$userId)
ratings$movieId <- as.factor(ratings$movieId)
movies$movieId <- as.factor(movies$movieId)
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
install.packages("RCassandra")
knitr::opts_chunk$set(echo = TRUE)
library(RCassandra)
conn=RC.connect(host = '127.0.0.1',port = 9042L)
RC.describe.keyspace(conn)
RC.describe.keyspace(conn)
RC.close(conn)
# Load H2O and start up a local H2O cluster
library(h2o)
h2o.init(nthreads = -1)
# Import movie lens datasets
# ratings file can be found here: http://grouplens.org/datasets/movielens/1m/
ratings <- h2o.importFile("/Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/rating_edx.csv", sep = ":")
ratings <- ratings[c(1, 3, 5, 7)]
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
# movies file can be found here: http://grouplens.org/datasets/movielens/20m/
movies <- h2o.importFile("/Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/movies.csv", sep = ",")
library('pander')
sub_ratings <- as.data.frame(ratings[c(1:5), ])
pandoc.table(sub_ratings, style = "rmarkdown", caption = "Ratings Dataset")
sub_movies <- as.data.frame(movies[c(1:5), ])
sub_movies$genres <- gsub("\\|", ",", sub_movies$genres)
pandoc.table(sub_movies, style = "rmarkdown", caption = "Movies Dataset")
h2o.hist(ratings$rating, breaks = seq(0, 5, 1))
## Group Data by movieId
ratings_per_movie <- h2o.group_by(ratings, by = "movieId", nrow("rating"))
h2o.quantile(ratings_per_movie$numberRatings)
## Group Data by userId
ratings_per_user <- h2o.group_by(ratings, by = "userId", nrow("rating"))
colnames(ratings_per_user)[[2]] <- "numberRatings"
# Load H2O and start up a local H2O cluster
library(h2o)
h2o.init(nthreads = -1)
# Import movie lens datasets
# ratings file can be found here: http://grouplens.org/datasets/movielens/1m/
ratings <- h2o.importFile("/Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/rating_edx.csv", sep = ":")
ratings <- ratings[c(1, 3, 5, 7)]
colnames(ratings) <- c("userId", "movieId", "rating", "timestamp")
# movies file can be found here: http://grouplens.org/datasets/movielens/20m/
movies <- h2o.importFile("/Users/pavantej/Desktop/SCIT/sem2/big data/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/movies.csv", sep = ",")
library('pander')
sub_ratings <- as.data.frame(ratings[c(1:5), ])
