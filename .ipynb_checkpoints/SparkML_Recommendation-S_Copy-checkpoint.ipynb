{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SPARK_HOME and PYLIB env var and update PATH env var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.4-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build __SparkConf__ object \n",
    "\n",
    "    Contains information about your application.  \n",
    "\n",
    "\n",
    "Create __SparkContext__ object \n",
    "    \n",
    "    Tells Spark how to access a cluster. \n",
    "    \n",
    "\n",
    "Create __SparkSession__ object\n",
    "\n",
    "    The entry point to programming Spark with the Dataset and DataFrame API.\n",
    "\n",
    "    Used to create DataFrame, register DataFrame as tables and execute SQL over tables etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf().setAppName(\"Movie Recommendation Application\").setMaster('local')\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Loading the dependent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.sql.functions import isnan, when, count, col, countDistinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Problem Statement\n",
    " Building a recommender system for movies with a data set from MovieLens.\n",
    "\n",
    "\n",
    "#### Data Dictionary\n",
    "\n",
    "Ratings Data File Structure (ratings.csv)\n",
    "-----------------------------------------\n",
    "\n",
    "All ratings are contained in the file `ratings.csv`. Each line of this file after the header row represents one rating of one movie by one user, and has the following format:\n",
    "\n",
    "    userId, movieId, rating, timestamp\n",
    "\n",
    "The lines within this file are ordered first by userId, then, within user, by movieId.\n",
    "\n",
    "Ratings are made on a 5-star scale, with half-star increments (0.5 stars - 5.0 stars).\n",
    "\n",
    "Timestamps represent seconds since midnight Coordinated Universal Time (UTC) of January 1, 1970.\n",
    "\n",
    "\n",
    "Movies Data File Structure (movies.csv)\n",
    "---------------------------------------\n",
    "\n",
    "Movie information is contained in the file `movies.csv`. Each line of this file after the header row represents one movie, and has the following format:\n",
    "\n",
    "    movieId, title, genres\n",
    "\n",
    "Genres are a pipe-separated list, and are selected from the following:\n",
    "\n",
    "* Action\n",
    "* Adventure\n",
    "* Animation\n",
    "* Children's\n",
    "* Comedy\n",
    "* Crime\n",
    "* Documentary\n",
    "* Drama\n",
    "* Fantasy\n",
    "* Film-Noir\n",
    "* Horror\n",
    "* Musical\n",
    "* Mystery\n",
    "* Romance\n",
    "* Sci-Fi\n",
    "* Thriller\n",
    "* War\n",
    "* Western\n",
    "* (no genres listed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the movies and ratings data and creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read data and create a dataframe\n",
    "ratingsData = spark.read.format(\"csv\")\\\n",
    "       .option(\"header\", \"true\")\\\n",
    "       .option(\"inferSchema\", \"true\")\\\n",
    "       .load(\"file:///home/1867B39/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/ml-latest-small/ratings.csv\")\n",
    "    \n",
    "moviesData = spark.read.format(\"csv\")\\\n",
    "       .option(\"header\",\"true\")\\\n",
    "       .option(\"inferSchema\", \"true\")\\\n",
    "       .load(\"file:///home/1867B39/20180701_Batch39_CSE7322c_Recommendation/ml-latest-small/ml-latest-small/movies.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratingsData.printSchema()\n",
    "moviesData.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total number of Columns and Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Columns = 4\n",
      "No. of Records = 100004\n",
      "No. of Columns = 3\n",
      "No. of Records = 9125\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of Columns = {}\".format(len(ratingsData.columns)))\n",
    "\n",
    "print('No. of Records = {}'.format(ratingsData.count()))\n",
    "\n",
    "print(\"No. of Columns = {}\".format(len(moviesData.columns)))\n",
    "\n",
    "print('No. of Records = {}'.format(moviesData.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at first 3 row of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|     31|   2.5|1260759144|\n",
      "|     1|   1029|   3.0|1260759179|\n",
      "|     1|   1061|   3.0|1260759182|\n",
      "+------+-------+------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratingsData.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moviesData.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+------------------+\n",
      "|summary|           movieId|               title|            genres|\n",
      "+-------+------------------+--------------------+------------------+\n",
      "|  count|              9125|                9125|              9125|\n",
      "|   mean|31123.291835616437|                null|              null|\n",
      "| stddev| 40782.63360397416|                null|              null|\n",
      "|    min|                 1|\"\"\"Great Performa...|(no genres listed)|\n",
      "|    max|            164979| İtirazım Var (2014)|           Western|\n",
      "+-------+------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moviesData.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the count of Distinct usersIds and movieIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different users: 671\n",
      "Number of different movies: 9066\n",
      "Number of different movies: 9125\n"
     ]
    }
   ],
   "source": [
    "print \"Number of different users: \" + str(ratingsData.select('userId').distinct().count())\n",
    "print \"Number of different movies: \" + str(ratingsData.select('movieId').distinct().count())\n",
    "print \"Number of different movies: \" + str(moviesData.select('movieId').distinct().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for null values at each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     0|      0|     0|        0|\n",
      "+------+-------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratingsData.select([count(when(isnan(c), c)).alias(c) for c in ratingsData.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+\n",
      "|movieId|title|genres|\n",
      "+-------+-----+------+\n",
      "|      0|    0|     0|\n",
      "+-------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "moviesData.select([count(when(isnan(c), c)).alias(c) for c in moviesData.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into training and test sets (30% held out for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataFrame[userId: int, movieId: int, rating: double, timestamp: int],\n",
       " DataFrame[userId: int, movieId: int, rating: double, timestamp: int],\n",
       " DataFrame[userId: int, movieId: int, rating: double, timestamp: int]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#ratingData_train, ratingData_test = train_test_split(ratingsData, test_size=0.30,)\n",
    "ratingsData.randomSplit([0.7, 0.2, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ALS model params\n",
    "\n",
    "\n",
    "1. numBlocks is the number of blocks the users and items will be partitioned into in order to parallelize computation (defaults to 10).\n",
    "2. rank is the number of latent factors in the model (defaults to 10).\n",
    "3. maxIter is the maximum number of iterations to run (defaults to 10).\n",
    "4. regParam specifies the regularization parameter in ALS (defaults to 1.0).\n",
    "5. implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data (defaults to false which means using explicit feedback).\n",
    "6. alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations (defaults to 1.0).\n",
    "7. nonnegative specifies whether or not to use nonnegative constraints for least squares (defaults to false).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als= ALS(userCol=\"userId\",itemCol=\"movieId\",ratingCol=\"rating\",coldStartStrategy='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on the test data\n",
    "predictions=model.transsform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+\n",
      "|userId|movieId|rating| timestamp|prediction|\n",
      "+------+-------+------+----------+----------+\n",
      "|   575|    148|   4.0|1012605106|       NaN|\n",
      "|   242|    463|   4.0| 956685706| 3.7861197|\n",
      "|   460|    471|   5.0|1072836030| 3.8607845|\n",
      "|   548|    471|   4.0| 857407799| 3.2966456|\n",
      "|   491|    471|   3.0| 940797129|  4.539845|\n",
      "+------+-------+------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = nan\n"
     ]
    }
   ],
   "source": [
    "evaluator= RegressionEvaluator(metricName=\"rmse,labelCol=\"rating\"), predictionCol=\"prediction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
